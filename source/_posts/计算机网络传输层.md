---
title: 计算机网络传输层
top: true
cover: true
toc: true
mathjax: true
date: 2021-07-12 11:52:37
password:
summary:
categories:
tags: 
	- 计算机网络
	- 抓包
	- 通用模式
---

## 1.1 概述和传输层服务

传输层位于应用层与网络层之间，起着承上启下的重要作用。概括的说，**传输层协议为运行在不同主机上的进程提供逻辑通信的功能**。而从TCP/IP协议族的组成来看，它向上使**进程间的通信成为可能**，向下**加强了网络层提供的尽力而为式**的服务。那具体传输层如何使用服务，并在此基础上加强，最后提供服务的呢？我们还需要继续勾勒这个蓝图：

在此之前，首先来看书中给出的例子——

有两个关系不错的家庭A和B，家庭A的5位家庭成员都会向家庭B的5位家庭成员写信。写好信后交由邮递公司将其送到家庭B的信箱中，家庭B的长子再将信从信箱中取出交给弟弟妹妹们。我们来对这个例子做一个类比：

两个家庭可以看做两个主机，弟弟妹妹们可以看做是应用进程，长子可以看做是传输层协议，邮递服务可以认为是网络层提供的服务，应用层的报文即是信的内容。

从这个案例中，我们可以提取出一些**有趣的信息**——

- 邮件服务有可能出现纰漏，比如会传错，丢失等，即`网络层传输的是不可靠的服务，它不对分组做有效力的保证`。
- 邮箱里的信件是乱序的，但通过长子来传递到弟弟妹妹的信件却是有序的，即`传输层协议会对可靠性做保证，而其应用的机制则是RDT原理`。
- 长子不需要跑去邮局取信件，而只需要定期检查邮箱就行啦。即传输层协议被定义在端系统，还是那句话，`网络核心的功能其实是在网络边沿实现的`。
- 如果邮局没有在规定时间内传递邮件，那在此期间在家里就不可能取到信件。即`传输层的服务明显受限于网络层提供的服务`。
- 如果邮箱中有很多信件，长子可以选择性的先取出一些邮件。即`传输层提供流量管理和拥塞控制的服务`。
- 长子在取邮件时，首先需要需要拆开信封，再取出信件。即`目标端可以实现解复用`。

除了上面将传输层当做**整体**看待来分析它的特点与实现以外，我们还需要将传输层拆解，广为人知的是，传输层提供TCP和UDP两个协议，

`TCP`：TCP提供的服务是可靠的，保序的，有拥塞控制，流量管理机制的，面向连接的，涉及复用与解复用，数据以**字节流**的形式传输。

`UDP`:   UDP提供的服务是不可靠的，不保序的，不面向连接的，数据以**数据报**的形式传输。

蓝图已经画就，我们来用笔墨筑起传输层的万丈高楼——

## 1.2 多路复用与解复用

我们在PC上可以同时运行QQ,网易云.它们是从属于不同的进程，所以当传输层向上层传输信息时，需要标识给哪一个进程，也就是需要使用**Socket来标识一个进程**，那向上传输的内容，除了Socket，显然还需要有报文。**报文中包含传输层的首部字段和MSG**。这里的描述其实就是解复用的过程，显然，我们在之前已经接触过。下面我们更具体地描述传输层的复用与解复用。

- `复用：`在源主机从不同的套接字中收集数据块，并**为每个数据块封装首部信息**，生成报文段，最终将报文段交付于网络层。
- `解复用：`将传输层报文段中的数据交付给应用进程的过程

也就是说，传输层的多路复用与解复用实现的就是`将主机到主机的交付服务延伸到应用程序到应用程序之间`，它关注的问题无非是**将报文传给谁，报文中都包括什么**。


![image-20210707210324385](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707210324385.png)

可以看出，复用与解复用的核心是通过套接字来完成的。而通过上一章节的知识，我们知道TCP和UDP的套接字所引用的信息是不一样的。我们分情况来看——

### 无连接的多路复用与解复用

我们通过图解来解析UDP多路复用的过程——

![image-20210707210337051](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707210337051.png)

`饮`：主机A中的传输层创建一个传输层报文，**报文包含应用程序数据，源端口号19157，目的端口号46428和其他两个值**。接着，传输层将该报文段传输给**网络层**，网络层再将报文段封装到一个**IP数据报**中，并通过网络链路交付给接收主机。

`啄`：接收主机传输层检查该报文段中的**目的端口号46428**，并将该报文段交付给端口号46428所**标识的套接字**。

这里有一点可能会引起**困惑**的地方：socket是如何参与这个过程的。首先明确的是，**socket是不被包含在报文段中的**。UDP的Socket包含目的IP，目的端口号，它仅用于处理源端口或者目标端口的**识别**，即**层间接口**。但报文是实际参与通信过程的。这里的socket就像是一个**开门的钥匙**。

### 面向连接的多路复用与解复用

同样的，开局一张图——

![image-20210707224235450](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224235450.png)

区别于UDP，TCP的socket所引用的信息是一个四元组，即——

![image-20210707224252958](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224252958.png)

额，PID就不用管了，当一个报文段被交付给应用进程时，它需要使用四元组的socket来判别报文段应该被交付给具体哪一个应用进程。

如果我们要求在传输层上只实现**必要的最简单协议**，那UDP完成符合这样的要求。UDP的全称是**用户数据报协议**。它仅在网络层的基础上提供**必要的复用，解复用，以及简单的校验和**。这使得它的功能基本上和网络层一致。

我们知道，网络层提供的服务是不可靠的，所以使用UDP的传输层提供的服务同样不可靠。这意味着它不需要握手，即不面向连接。数据有可能发生乱序，重复。而假设发生了这种错误，客户端如何处理呢？它会直接**丢弃**。

这种简洁的设计会有它的用武之地吗？当然，**简洁也是一种优雅**，它简单所以头部信息少，传输快，它不需要建立连接，也自然没必要维护连接的状态。甚至一些应用是在UDP的协议上构建的——

![image-20210707224304322](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224304322.png)

那这是否意味着基于UDP的应用是不可靠的呢？不完全是，**在应用程序做可靠传输的处理**是一种可选的方式。

我们再来拨云见日地看看UDP的报文结构：

![image-20210707224316644](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224316644.png)

值得一提的是UDP仍然提供了必要的简单检错机制，即**校验和**，来看校验和的原理——

![image-20210707224330412](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224330412.png)

即我们在源端得到测试的和，如果有进位，则再回卷得到和。数据报传输到目标端以后，目标端将**校验和的反码与源端得到的校验和相加**，如果相加为全1，则校验通过，反之不通过。

## 1.4 重点：可靠数据传输原理

### 问题描述

可靠数据传输是一个**一般性的问题**，它不仅在传输层使用这个机制，在网络层和应用层也可以实现。而下一个小节中我们将以最通用的传输层为例介绍可靠数据传输协议RDT。

在编程时，我们通常使用这样的思维：即`首先将具体问题转化为抽象的数学问题，再使用编程语言将数学问题实现`，在学习rdt时，这种思路同样适用。

首先来看可靠数据传输面临的场景：对于应用层来说，传输层通过可靠数据传输的机制，并使用**可靠的信道**来向应用层提供服务——

![image-20210707224342304](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224342304.png)



`那这个可靠的服务是如何实现的呢`？显然是通过调用下层服务。从而对本层服务做加强来实现的，我们将这一过程**抽象成原语实现**，我们将这些原语具体描述，他们发挥着这样的功能——

- `rdt_send:`被上层调用，将数据交付给下层的发送方实体。
- `udt_send:`被rdt调用，将分组通过不可靠的信道发送给接收方。
- `rdt_rcv:`分组到达接收方时被调用。
- `deliver_data:`被rdt调用，将数据交付给上层。

我们需要通过rdt来实现**发送方和接收方动作的抽象**，但这种抽象是基于不可靠的信道，它可能会发生**乱序，重复，篡改**等问题，直接给出解决方案着实有点难为人。所以这里引入了一种处理复杂问题的思路，即**渐进式解决**。

`具体的说，我们一层层地去掉那些美好的假设，然后在一个可行方案的基础上逐渐完善`。我们的任务仅仅是实现一个能够完成必要功能的rdt协议，所以双向传输可以简化为单向传输，此外，给出有助于解决问题的通用模型也势在必行。也就是有限状态机FSM，在学习数字系统设计时，接触过使用**FSM描述的空调状态机**。不想除了考试，居然还能有缘再见。在课堂终于学到有用的知识了。。。

FSM是这样设计的：

![image-20210707224353943](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224353943.png)

至此，前置知识就完结了，故事的大幕就此拉开——

### rdt1.0

这里`假设信道完全可靠`，它没有比特出错，甚至不会分组丢失，此时的rdt协议,恕我说句：工具人~。

用状态机来描述一下此时的发送方与接收方——

![image-20210707224406899](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224406899.png)

这个显然还没有复杂度需要详细描述的地步，next~

### rdt2.0

在2.0版本，我们就要抛弃掉一些幻想，这时候的信道不那么可靠，它可能会发生`比特的错误`。之前在聊UDP时谈及UDP报文结构中使用校验和来做差错检测，当然TCP也有这个机制。检测出来后，怎么更正呢？自然是重发，那`如何标识出错的状态`呢？

这就需要引入`标记量`。假如接受方检测到比特出错，就发送显示的发送错误标志，也就是`NAK`，俗称：反向谢谢；而当检测后发送无误，就发送显示的发送正确标志，这回是正向的谢谢：`ACK`。

同样的，向量机描述——

![image-20210707224420197](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224420197.png)

这时，状态机已经没那么友好了，我们简要描述一下——

- `发送方：`当rdt接收到应用层的数据后，将`数据与校验和组成传输报文`通过不可靠的信道发送给接收方，然后发送方等待接收方的回应。当等待到的是ACK时，继续等待上层调用。
- `接收方：`接收方接收来自不可靠信道的数据，然后`做校验`，当校验出错时发送NAK,校验正确时发送ACK。

### rdt2.1

咦，怎么又出现了2.1，自然是因为2.0实在不堪大用。2.0版本的确相比1.0版本迈出了一大步，但它本身存在致命的缺陷，也就是**ACK,NAK本身也有可能发送错误**。rdt的机制应该也必须是健壮的，所以当接收到不可识别的信息时**有必要重发数据包**。所以对数据包的标识就这么顺水推舟的发生了.即**对分组加序号**。但这里只使用1位，即2种可能结果标识正在处理的分组。这是因为目前仍处于**STOP AND WAIT阶段**，一次发送一个数据包，用0和1来标识要处理的数据包就行啦。但如何处理重复呢？**丢弃**发送时间较早那个的数据包。

#### 接收方处理出错的ACK/NAK

老规矩——

![image-20210707224431777](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224431777.png)

这时接收方在2.0版本的基础上增加了对分组序号的识别，再来看发送方的处理——

![image-20210707224444037](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224444037.png)

看似很复杂，但实则只是穷举了对于不同分组的类似处理，毕竟只需要考虑两个分组，可以任性地穷举。来看下具体的场景——

![image-20210223150554157](http://qnuez6z2b.hn-bkt.clouddn.com/typora/image-20210223150554157.png)

### rdt2.2

2.2版本本质上和2.1版本并无二致，但出于简洁的考虑，只使用ACK，而不用NAK。那具体怎么操作的呢？

假设有这样一个场景——

> 发送方发送**数据包1**，接收方检测出错了，所以发送**ACK0**给发送方。发送方默念一句你丫的，然后重新发送数据包1.双方继续和谐地传递着数据包。

![image-20210707224454789](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224454789.png)

一看就会的图解——

![image-20210707224504993](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224504993.png)

这里不再给出状态机描述，它的确适合转换为编程语言。但与人交互还是上图更友好些。

### rdt3.0

解决了乱序，比特出错。仍旧还有**分组丢失**的问题，如果按照rdt2.2机制，分组丢失后发送方接收方都鸦雀无声，陷入了**死锁，浪费CPU资源**。所以需要加入**超时重传机制**。

即当分组发送出去后，计时器开始倒计时，如果计数到0还没有收到响应，那就重传。机制的核心在于**计时的确定**，**网络状态是很难预测**的，它的拥堵状况可以类似于高斯分布，我们需要使用数学中概率论的知识尽可能确定时间。当然，一个相对准确的计时器还需要**相当长的路要走**。

诚然，凡事讲究善始如终，此处应有状态机——

![image-20210707224518042](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224518042.png)

1. 首先发送方等待应用层调用，传输层组织好报文结构后，通过不可靠的信道将分组0传输给接收方，并启动超时定时器；
2. 状态切换到等待ACK0的响应，如果超时或出错(ACK1)，则重传，如果接收到ACK0，状态切换至等待应用层调用1；
3. 偷懒一手，同上。

------

至此，rdt3.0已经是用于传输单个分组的无懈可击的协议，但在信道带宽大的情况下，rdt3.0的性能非常感人。这就好比八车道的高速公路全程只准跑一辆自行车。这显然很难以忍受，所以如何一次性发送多个分组而无须等待确认是必须要解决的问题。

![image-20210707224528848](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224528848.png)

我们将这种发送多个分组可以看做是填充到一条流水线中。因此解决这个问题的机制被称为**流水线协议**。流水线协议在rdt3.0基础上增加了**传输分组的粒度**。但它同时带来的问题可一点也不少——

- 分组的序号显然只用0和1是不够的，必须**扩大分组序号的范围**，来唯一地标识一个分组；
- 分组传输与接收的速率不一致，需要在接收方增加**缓存机制**，此外，发送方在发送分组以后可能处于两种状态：`等待确认,确认完成`。所以发送方的分组需要分区，即发送方也需要缓存机制；
- 当分组出现损坏，丢失，延迟时如何处理呢？根据场景有两种可选的方式：`GBN(回退N步)和SR(选择重传)`.

------

这两种处理差错的方式又都是基于**通用的滑动窗口**来实现的，滑动窗口是在**缓冲区的基础上**运作的，我们先来了解发送缓冲区及接收缓冲区——

- `发送缓冲区：`缓冲区即是内存中的一块区域，它有大小属性，这里的发送缓冲区大小可以为1，即RDT3.0,当大小>1时，即为流水线协议。这里的发送缓冲区用于**存放已发送未确认的分组**，以便用于检错重发或超时重传。
- `接收缓冲区：`是为了解决分组在信道中传输的速率与接收方接收的**速率不一致**的问题所引入的。它的大小为1时即为RDT3.0,当发送缓冲区大小>1时，接收缓冲区可以为1，此时为GBN协议，如果接收缓冲区>1,则为SR协议。

那如何表示缓冲区动态传输的过程呢？这就需要引入滑动窗口——

### 发送窗口

滑动窗口用来表示`发送缓冲区的范围`，即实际的`已发送未确认的分组个数`，我们通过图解来认识这个动态的过程——

![image-20210707224540604](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224540604.png)

此时，没有分组发送，缓冲区大小N=5，滑动窗口前沿=后沿，窗口大小=前沿-后沿=0。

![image-20210707224551296](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224551296.png)

接着，一个分组被发送，前沿移动一位，滑动窗口大小=前沿-后沿=1.此时分组0处于已发送未确认状态。

![image-20210707224601189](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224601189.png)

此时，5个分组都被发送，缓冲区已满，滑动窗口大小=前沿-后沿=5=缓冲区大小。

------

这个过程我们是假设没有分组收到确认，现在我们打开潘多拉魔盒，认为已经有分组已经收到确认，情况就有所不同了——
!![image-20210707224616355](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224616355.png)

这时，`分组0得到确认，窗口后沿移动`，此时前沿仍然指向最后一个进入缓冲区的已发送未确认分组。

![image-20210707224627690](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224627690.png)

然后，分组1也得到确认，窗口后沿移动。有两个分组5,6被发送，进入缓冲区等待确认。窗口前沿移动到6的位置。

------

### 接收窗口

发送窗口告一段落，来类比地看接收窗口，接收窗口可以控制哪些分组可以接收：

- `收到的分组序号落在接收窗口内可以接受`；
- 落在接收窗口外，则丢弃。

此外，接收窗口根据出错的概率分为两种情况，对应两种协议——

#### GBN

接收窗口的尺寸等于1，即`只能顺序接收`：

![image-20210707224639851](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224639851.png)

接收窗口首先在分组0的位置，此时只有分组0的会被接收，如果接收到的是分组1，则丢弃。假设接收方接收到分组n,则表示小于等于分组n的所有分组都已经被接收，即**累计式确认**。

#### SR

接收窗口的尺寸大于1，可以乱序接收：

![image-20210707224650324](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224650324.png)

起初，接收窗口中有分组0,1,2,3.收到分组0,1后，接收窗口向前滑动。但如果分组没有按序到来，会发生什么呢？

![image-20210707224701886](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224701886.png)

可以看到，当高序号的分组到来后`，仍旧将其缓存，但并不移动滑动窗口`，只有当低序号的分组到来后，窗口才会整体后移——

![image-20210707224711512](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224711512.png)

最后，可以总结出SR协议为非累积式接收。

------

#### 正常情况下的窗口互动

![image-20210707224721902](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224721902.png)

#### 异常情况下的窗口互动

![image-20210707224736296](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224736296.png)



![image-20210707224827566](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224827566.png)



#### 用FSM描述的GBN

1. 发送方

   首先声明这些变量代表的含义：`N为窗口长度，base为窗口后沿，nextseqnum为满足发送条件但因缓冲区已满没有发送的分组序号`，

![image-20210707224840765](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224840765.png)

2. 接收方

   ![image-20210707224850680](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224850680.png)

#### 运行中的SR

![image-20210707224903011](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224903011.png)

### 总结

GBN适用于`出错率低`的场景，`而链路容量大，回退代价高`的场景则是SR更优。

![image-20210707224915038](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224915038.png)

## 1.5 面向连接的传输——TCP

在对TCP有大致的纹路了解后，我们进入TCP正式的探索。本着结构决定功能的特点，从TCP的段结构起笔，渲染TCP的可靠数据传输，进而浓墨于流量控制机制，最终落笔于连接管理。

`TCP提供的是点到点，可靠的，管道化的，按序的字节流，拥有流量控制机制，面向连接的服务。`

### 段结构

TCP的报文段由一个**首部字段和数据字段**构成，数据字段即是应用层的数据，那这部分数据是源数据根据怎样的规则划分的呢？这里引入**最大报文段长度MSS**的概念。TCP会将要传输的文件分为若干个MSS。**MSS的长度**通常由**本地发送主机发送的最大链路层帧长度**来设置。在确定数据部分后，TCP为每个客户端数据配上一个**TCP首部**，从而形成多个TCP报文段。

![image-20210707224931500](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707224931500.png)

具体来看每个字段：

- `源端口号：`TCP提供的是进程之间的逻辑通信，而标识进程的即是端口号，标识源端口号就相当于给出了数据**复用**的路径。

- `目的端口号：`同样的，只有给出目的端口号，在接收方才能完成**解复用**的工作。

- `序号：`TCP把数据看做一个**无结构，有序的字节流**。而为了来标识每个报文段(`MSS`)的首字节在整个字节流中的位置，或者说偏移量，就引入了序号的概念。该序号的范围为**2的32次方**，可见冲突的几率比我中彩票还低~

  ![image-20210707225012629](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225012629.png)

- `确认号：`在可靠数据传输中，我们使用ACK来作为确认字段，但ACK只能表示接收方对接收到数据的回应，而实际的传输是全双工，且高并发的。所以接收方的确认号将**确认与下一次传输的数据相结合**作为确认号。也就是说，假设确认号为2000,即表示**期望收到的下一个字节的序号**，这里给出的序号同样也具有**GBN累计确认**的意义。

  我们试着使用序号与确认号来描述简化的传输过程——

  ![image-20210707225024780](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225024780.png)

  即主机A发送序号42及对于序号79的确认，主机B收到后，发送对于序号42的确认，即ACK=43，且发送主机A期望的79，即seq=79.

- `接收窗口：`该字段用于**流量控制**，即指示接收方愿意接受的字节数量，在抓包的时候任一数据发送源都会使用**Win字段**来告诉另一方自己接收窗口的大小。

- `CRC校验和：`在UDP部分谈及过，用于**检错**。

而从进程通信的`流程框架`来看，TCP报文段又会经历怎样的**复用与解复用**呢——

在形成报文段以后，这些报文段被下传给网络层，网络层将其分别封装在**网络层IP数据报**中，接着被发送到网络中，TCP在另一端接收报文段，该报文段被放在该**TCP连接的接收缓存**中，应用程序从缓存中读取数据流。

### 可靠数据传输

了解了确认号与序号，可靠数据传输的纹路已经逐渐明晰。在学习通用的rdt时，我们谈及当一个分组丢失时，超时重传机制是有必要的，这在TCP的机制中同样适用。但在TCP的机制中，我们需要将超时重传的机制具象化，即真正高效地使用。

如何来估计超时重传的往返时间？**定时器RTO**应该设置多长时间？是否需要为每一个分组都设置一个定时器呢？我们来渐进式地解答——

1. 显然，定时器设置的时间应该是**大于往返时间RTT**的，所以我们可以随机地选取某一个RTT作为**SampleRTT**,但由于路由器的拥塞和网络负载均衡的特点，SampleRTT波动是很大的，所以为了更趋近于真实RTT，我们引入SampleRTT的均值EstimatedRTT。通过这两个标量，可以近似得到这样的公式：
   $$
   EstimatedRTT=（1-a）•EstimatedRTT+a•SampleRTT
   $$
   这里的a推荐值为**0.125**，将通过公式得到的均值称为之**指数加权移动平均**。

2. 这里直接给出公式——
   $$
   Timeoutinterval=EstinMrtedRTT+4•DevRTT
   $$
   这里的DevRTT是为了解决波动问题，而引入的一个SampleRTT与EstimatedRTT之间差值。

3. TCP并不会为每个分组都维护一个定时器，因为高并发的发送维护定时器的代价是很大的，因此TCP使用了**单一重传定时器机制**。即只为**发送缓冲区中最古老的已发送未确认分组**维护定时器。

至此，TCP可靠数据传输的自肖像已经变得丰满起来。我们不妨在已经构建框架的前提下给出一个最简化的TCP发送方——
![image-20210707225039262](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225039262.png))

即当超时定时器触发以后，发送方会传输**至今没有得到确认的最小序号分组**。即这里的机制又是类似于**选择性重发SR**。在重发后，超时定时器又会与当前没有得到确认的最小序号分组相关联。此外，还有一种情况，即缓冲区为空，即所有的分组都已得到确认，此时需要重启定时器。

通过下图来看简要的交互：

![image-20210707225051029](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225051029.png)

另外，我们来穷举关于ACK的几种情况及相应的处理方式——

| **接收方事件**                                         | **TCP接收方动作**                            |
| ------------------------------------------------------ | -------------------------------------------- |
| 所期望序号的报文段按序到达，期望序号之前的都已得到确认 | 延迟的ACK，即对另一个按序报文段最多等待500ms |
| 有期望序号的报文段到达，另一个按需报文段等待发送ACK    | 立即发送单个累积ACK，以确认两个按序报文段    |
| 比期望序号大的报文段乱序到达，检测到数据流的间隔       | 立即发送重复ACK，指明下一个期待字节的序号    |
| 能部分或者完全填充接收数据间隔的报文段到达             | 若该报文段起始于间隔的低端，则立即发送ACK    |

这个简化的TCP交互是默认不存在重复确认的，但实际上重复确认的情况是有可能出现的，TCP针对这种情况也给出了**快速重传机制**。

收到**重复确认**往往是因为**定时器设置的太大**，接收方没有收到某个分组，但在定时器时间内仍会收到乱序到达的其他分组，这时接收方就会发送冗余分组，当发送方接收到**三个冗余确认**后，就会在定时期间**重传最小序号的报文段**。

![image-20210707225101991](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225101991.png)

再来看下快速重传的伪代码——

![image-20210707225112511](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225112511.png)

即接收方收到ACK，判断ACK与窗口后沿的关系，假如**ACK大于窗口后沿，则将窗口后沿滑动**，将**定时器与新的报文段关联**。否则，也就是ACK重复的情况，则记录ACK重复的个数，当其等于3时，触发快速重传机制。

### 流量管理

传输层在将数据解复用以后，不是直接交付给应用程序使用，而是将其放置在**接收缓冲区**内，上层应用再**从缓冲区中读取数据**。但当从发送方发送来的数据太多就有可能**淹没接收缓冲区**，导致报文段丢失，因此，约定发送方的发送速率与接收方的接收速率是必须的，这种**为了匹配速率的机制就称为流量控制**。

流量控制机制是通过互相告知缓冲区可用空间来实现的。那如何告知呢？即是通过接收方向发送方发送的报文段中的**rwnd字段**，它表示了**接收缓冲区中可用的空间**。

![image-20210707225128655](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225128655.png)

我们将rwnd再具象化，即它是通过什么来实现的呢？接收窗口！！！但这里的接收窗口和rdt中的接收窗口还是有所区别的。为了量化接收窗口的大小，我们还需要引入两个变量：

- `LastByteRead`:主机B上的应用进程从缓存读出的数据流的最后一个字节的编号。
- `LastByteRcvd`:从网络中到达的并且已放入主机B接收缓存中的数据流的最后一个字节的编号。

那么接收窗口就可以表示为：
$$
rwnd=RcvBuffer-[LastByteRcvd-LastByteRead]
$$

### 连接管理

我们来深入了解如何建立和拆除一个TCP连接，首先，我们需要建立一些共识，也就是连接都需要做什么？

在socketAPI的编程中，我们需要维护两个套接字，即连接是针对双方而言的，**每一端可以看做维护一个半连接**，所以在建立TCP连接时，两端都有**告诉对方我要建立连接**的诉求。除此之外，还需要**为连接配置资源**，因为连接就意味着马上会有数据传输，所以**缓冲区自然是需要**的，此外，**序号和确认号也是必选项**咯。

### 三次握手

好啦，实际地去建立连接时，首先先入为主的想法是两次握手——

![image-20210707225141658](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225141658.png)

但两次握手面临着很多问题：

- 假如接收方的确认超时了，此时发送方会重发连接建立请求。但我们注意到**接收方的机制简言之就是收到连接请求则同意建立**。也就是说，虽然确认超时了，但接收方仍会维护一个**半连接的状态**及对应的资源。
- 在上面状况的基础上，假如发送方接收到确认后，发送数据data，而接收data的接收方的状态为新的连接，那么此时**新的连接接收的是老连接的数据**。

这些问题的症结本质上是**半连接的孤立**，那么如果**在双方半连接的基础上增加两个半连接的交互**，那问题就迎刃而解了。三次握手就是基于这样的思想实现的。我们来详细剖析三次握手的详细过程——

1. `第一次握手：`客户端的TCP首先向服务器端的TCP发送一个特殊的TCP报文段。该报文段中**不包含应用层数据**。但是在报文段的首部中的一个标志位（即**SYN**比特）**被置为1**。因此，这个特殊报文段被称为**SYN报文段**。另外，客户会**随机地选择一个初始序号**（client_isn）,并将此编号放置于该起始的TCPSYN报文段的序号字段中。

2. `第二次握手：`服务器会从该数据报中提取出SYN报文段，为该TCP连接**分配TCP缓存和变量**，并向该客户TCP发送允许连接的报文段。这个允许连接的报文段**也不包含应用层数据**。但是，在报文段的首部却包含**3个重要的信息**。

   1. SYN比特被置为1。
   2. TCP报文段首部的确认号字段被置为**client_isn+I**
   3. 服务器选择自己的初始序号（**serverjsn**）,并将其放置到TCP报文段首部的序号字段中。这个允许连接的报文段实际上表明了：**“我收到了你发起建立连接的SYN分组，该分组带有初始序号clientjsno我同意建立该连接。我自己的初始序号是serverjsnon**

   该允许连接的报文段被称为**SYNACK报文段**.

3. `第三次握手:`在收到ACK报文段后，客户也要给该连接**分配缓存和变**量。客户主机则向服务器发送另外一个报文段；这最后一个报文段**对服务器的允许连接的报文段进行了确认**（该客户通过**将值serverjsn+1放置到TCP报文段首部的确认字段**中来完成此项工作）。因为连接已经建立了，所以该**SYN比特被置为0**。该三次握手的第三个阶段可以在报文段**负载中携带客户到服务器的数据**。

![image-20210707225201937](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225201937.png)

嗯，熟悉的FSM环节——

![image-20210707225214552](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225214552.png)





------



### 四次挥手

天下没有不散的宴席。TCP连接也不能免俗。相比于三次握手，四次挥手还是水到渠成的，双端都可以主动发起断开连接的请求，然后**双方断开自己维护的半连接**即可，同样的，我们来复现这个过程——

1. 客户端进程向服务器进程发送一个特殊的报文段，该报文段中首部标志位**FIN置1**；
2. 服务器接收该报文段后，**其ACK比特置1**.
3. 反向同理。

![image-20210707225225357](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225225357.png)

## 1.6 拥塞控制原理

------

### 前言

在rdt可靠数据传输机制中，分组丢失是不可避免的，而**分组丢失的原因通常是由网络拥塞**，当路由器的缓存被占满后，后来者将会别抛弃，本质上说这种状况是因为网络是不可控的，很难从端系统获知网络的状况，但发送方又本着`多多益善`的方式在加剧网络的恶化。

为了避免网络拥塞，TCP使用了怎样的机制，这种处理机制出发点是什么，它针对性地解决了哪些问题，如此种种。要解决这些问题，我们仍要铺好第一块砖石——

`网络拥塞的定义`：太多的数据需要网络传输，超过了网络的处理能力。

### 拥塞原因与表现

这里我们仍使用渐进式分析问题的思想，一个不会发生分组丢失的网络是怎样的呢？

- `路由器缓存无限大`
- `端系统可以了解网络的状况并作出调整。`

- `所有分组都可以不超时的到达，所以不需要重传`

先来看路由器缓存，假设路由器缓存无限大，那分组就不会被丢弃。这时假设有两个发送端通过一条链路(带宽为R)发送数据，那么它的吞吐量和延时表现为这样——

![image-20210707225238081](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225238081.png)

可见，即便在理想状态下，当超出链路的承载能力后，`流量强度变大，排队延时激增`。硬件条件这是不可逾越的天花板。所以我们很难控制不发生拥塞，而要从拥塞发生后的处理技巧入手。

接着，我们去掉缓存无限的假设，这时分组丢失就变得无可避免，分组丢失就意味着重传，而`重传导致链路中重复的分组`，也就是不必要的分组增多，直接使得`发送方比接收方更高的发送速率`，导致本就不宽裕的链路带宽更显的捉襟见肘。另外，超时重传作用的结果也是一样的。

最后，我们设想在类似`进程发生死锁`的一种情景，每个发送方占用着别的发送方需要的链路带宽，而别的进程也占用着自己需要的链路带宽，如果人的欲望一般，我们知道这条路是错的，但贪念仍在驱使着躯干向前。

### 拥塞控制的方式

针对上面的状况，一般采用两种控制拥塞的方法——

- `端对端的拥塞控制：`TCP就使用这种策略。端系统根据`延迟和丢失事件`推断是否有拥塞。
- `网络辅助的拥塞控制：`路由器通过`置位`的方式显示的告诉发送端可以采用的速率。

来通过实际的**ATM ABR场景**认识下这两种方式是怎样实际运转的：

我们知道，在网络中传输的数据粒度是有区别的，专线更多使用线路交换的方式，而通用的则是分组交换的方式，这种在银行中大行其道的ATM ABR线路则使用数据粒度`介于线路交换和分组交换的粒度大小`，更具体地说，它传输的最小单元是`53个的比特`。

**ABR(available bit rate)**提供的是弹性服务，它可以`根据网络的负载实时调整发送速率`。如果发送方路径轻载，则发送方就使用尽可能多地利用贷款。如果发送方路径阻塞，发送方限制速率至一个最小保障速率。

那网络中的拥塞状况是如何被获知的呢？通过RM信元，即**资源管理信元**。

它由发送端发送，在数据信元中间隔插入，通过该信元特定的比特位来作为网络辅助，这种行之有效的比特位分别是：

- `NI bit:`即no increase in rate。
- `CI bit:`即congestion indication拥塞指示。

发送方发送的RM信元被接收方返回，`接收方仅用作中转`使用。另外，之前谈及信元可以返回给发送方最小发送速率，这是如何实现的呢？

通过RM信元中的2个字节`ER(explicit rate)字段`.拥塞的交换机会降低ER的值，最终返回给发送方。

------

## 1.7 TCP拥塞

在上一小节中，我们聊了通用的拥塞控制机制，也就是：**端系统处理**，**网络辅助的拥塞控制**。同时对网络辅助的案例做了简单描述，这一小节，我们将展开讲述在端系统如何处理拥塞。

更具体地说，是**TCP的拥塞控制机制**。而在开始之前，我们先解决一个前置问题：TCP`为什么不在网络核心通过使用辅助信元的方式实现拥塞控制`。其实，纵观整个网络架构，复杂性都是在传输层及其以上提供的，也就是说，`网络层不会向上层应用提供显式的拥塞控制机制`。

那TCP的拥塞控制机制是怎样实现的呢？不着急，本着先有问题，再有方案的思路，我们先来回答TCP拥塞机制面临的**三大问题**——

- `如何感知到拥塞`

  网络拥塞的最终结果是分组丢失，而导致分组丢失的原因却有一些区别——

  1. 假如到达路由器的分组过多导致缓冲区已满，**分组就会被丢弃**。此外，有可能分组在传输时比特反转，接收方认不出来这是啥，那也会将其丢弃。这两种情况的直观表现都是超时，这种`拥塞情节严重`，发送方明显被动。
  2. 当发送方连续收到4个ACK信号，也就是**3个冗余ACK**时，就会触发快速重传机制，这时还没有超时，发送方主动出手降低损失，姑且称其`轻微拥塞`。

- `如何对速率做调整`

  那明确了问题，如何针对两种拥塞做出发送速率的调整呢？在**RDT**中，我们引入`接收窗口rwnd`来限制接收分组，这里我们也采用类似的机制，引入`拥塞窗口cwnd`。类比接收窗口表示能够接收分组的上限，拥塞窗口表示的即是——

  ![image-20210707225253295](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225253295.png)

  是不是似曾相识，发送窗口表示的是**实际的**已发送未确认的分组数量。而拥塞窗口就如同在对发送窗口做**动态调整**，除此之外，别无二致。那确定了拥塞窗口的值，发送方的发送速率也可以得出来——

  ![image-20210707225302111](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225302111.png)

  

- `通过怎样的算法对速率做调整：`

有了衡量拥塞的标志，接下来就需要通过拥塞状况触发动态调整啦，这里的动态调整，就是广受赞誉的**TCP拥塞控制算法**。

该算法分为三部分：慢启动，拥塞避免，快速恢复。我们详细来聊聊——

- `慢启动：`

  TCP会将cwnd的值`初始化为一个2/3/4MSS`(具体由MSS的大小决定)的值，但显然，这点速率是不够打的，所以当分组首次被确认后，会以`指数级的增长趋势`尽快加速，直至超时后打回原形，也就是1个MSS.这时，TCP还会维护一个**慢启动阈值**，也就是警戒值，它的值为**cwnd(max)/2**，接着，开始下一次拥塞控制，当cwnd的值指数增加至慢启动阈值后，不再鲁莽地指数级增长，而是维持`线性增长`。

  ![image-20210707225311975](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225311975.png)

  这种线性增长的机制就是拥塞避免——

- `拥塞避免：`

  那拥塞避免什么时候结束呢？和慢启动一样，拥塞避免阶段在触发超时后会重新开始SS慢启动阶段,这时，慢启动的阈值也势必会更新。

  再来讨论下发送方收到**3个冗余ACK**的状况——

  它的处理机制显然没必要像拥塞时那么剧烈，只需要在触发快速重传后，记录慢启动阈值，然后`直接从阈值开始线性增加`进入快速恢复阶段——

- `快速恢复：`

  所谓的快速恢复无非是针对两种拥塞状况的不同种处理，在上面已经提及，就不再赘述。

  1. 超时重传：RFC建议将拥塞窗口降至1个MSS，而由慢启动过渡至拥塞窗口的值就有讲究了，应该调整至没别确认的数据量的1/2,但不能小于两个MSS
  2. 快速恢复：不会处理拥塞窗口的值；

接下来就是小总结环节——

![image-20210707225324365](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225324365.png)

再将两种情况汇总，就有了下图——

![image-20210304182714108](C:\Users\zyz\AppData\Roaming\Typora\typora-user-images\image-20210304182714108.png)



### TCP吞吐量

这里我们取快速恢复阶段的数据量均值作为参考(慢启动指数级的增加实则很快，也导致实际传输的流量不多)，即——
$$
一条连接的平均吞吐量=3/4*W/RTT
$$
另外也给出在`经过高带宽TCP，且丢包率为L的情况`下，吞吐量的描述——
$$
一条连接的平均吞吐量：1.22*MSS/RTT/根号下2
$$

### TCP公平性

太饿了，去吃饭，偷懒一手——

![image-20210707225338648](https://gitee.com//future727/imgs/raw/master/zyz_img3/image-20210707225338648.png)

也就是多个TCP连接时，网络状况会趋向于`带宽均分`。

而如果一个链路中既有使用TCP的服务，也有使用UDP的服务，那对于TCP是不友好的，因为`UDP百无禁忌`，它没有拥塞控制机制，如果有可能，UDP会一点点的蚕食掉带宽，而最终导致更恶劣的后果，可见，**不限制贪欲最终会陷入恶性循环**。但这种机制也并非一无是处，流媒体就表示这是我的菜，因为`音视频应用起码泵出数据的速率是恒定`的，即便数据会丢失。

------

## 抓包番外

### 简单的代价——UDP



### DNS那些事

![image-20210506232028231](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210506232028231.png)

DNS常用的**应用场景**有两种：

- `CNMAE:`即将一个域名映射到另一个域名，

  ![image-20210506234636802](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210506234636802.png)

- `A：`请求获取域名对应的IP地址

  ![image-20210506234517700](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210506234517700.png)

当DNS在缓存中没有找到要查询的记录后，就会发起**DNS查询**，查询有两种：递归查询，迭代查询。假如我们向一个`不权威的DNS服务器发起递归查询请求`，我们只会与这个不权威的DNS服务器交互，而`无从得知它的查询结果是否可靠`。迭代查询则会相对安全一些，因为客户端首先会查到根服务器的地址，再从根服务器查到权威服务器，然后从权威服务器查询。。。直到返回想要的结果。

它的**响应**一般包含这些字段：

![image-20210506235701873](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210506235701873.png)

再来聊一些生僻的：**DNS循环工作模式**——

假如某个网站有10台Web服务器，管理员可以在DNS创建10个同名记录指向这些服务器的IP，由于不同客户端查到的结果顺序不同，而且一般会选用结果中的第一个IP，所以大量客户端就会被均衡的分配到10台Web服务器上，也就是`负载均衡`咯。

再来说说**DNS的缺点**，为人所知的`DNS放大攻击`就是缺陷之一，假如有这样的场景：我们由包发出去的请求只有少许字节，但收到的回复却高达几千字节，这种情况非常值得我们警惕。

### 老生常谈的TCP

![image-20210506235956824](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210506235956824.png)

这个包抓的还是`恰如其分`的，它完美的涵盖了三次握手与四次挥手的7个包，同时出现的`乱序问题`也印证了TCP的强大之处。接下来我们分别从三次握手和四次挥手来分析它的细节——

**三次握手**：

- `SYN报文段`

  在这个帧中，包含了Seq,Win，Len等字段，显然`Seq表示随机选择的报文段的初始字节偏移量`，而Win就比较有意思了，我们可能更熟悉它的另一个名称：rwnd，也就是说`Win就是接收窗口的大小`，只不过描述字段有区别，至于Len字段，见名知意，它描述了报文段的长度，但这并不包含报文头部的长度，所以`Len为0只能说明没有数据传输`。

- `SYN/ACK报文段：`

![image-20210507092224812](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210507092224812.png)

显然，TCP报文段（一个MSS长度）的`头部包含32个字节`，而我们常说的`XX报文段其实就是通过置位来标识`的。

- `ACK报文段`

  ![image-20210507093012217](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210507093012217.png)

  我们试图再发现一些新颖的事物，在这个窗口我们看到`一个包被接口过滤器（网口）收到的完整过程`，它依次经历了物理层，数据链路层，网际层，传输层。

**四次握手**

- `SYN/ACK报文段：`

  ![image-20210507093632419](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210507093632419.png)

  显然，在发送该报文段后`不再发送数据，但仍然可以接收数据`。

- `ACK报文段`

  ![image-20210507093904412](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210507093904412.png)

  显然，ACK包乱序了，但它仍可以被接收，这依赖于`TCP的累计确认`，也就是说TCP只关心发送的最古老的的那个包有没有被收到，如果`有乱序的包到达，它会将其放置在接收窗口而不给与确认`，在收到最古老的的那个包后，它会接收该包并累计确认，应用层再从接收窗口中读取这些包。

最后再来看一个非常有用的命令：**netstat**

![image-20210507095047707](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210507095047707.png)

这是我使用netstat命令陈列出来的TCP连接状态，我们发现有这样几种状态：

1. TIME_WAIT:

   TIME_WAIT又称`2MSL状态`(报文段最大存活时间)，被动关闭方在收到FIN并回复ACK后会进入该状态，它的作用主要有两个：

   1. 允许老的重复报文分组在网络中消逝，`避免新连接接收老连接的数据`。

   2. 保证TCP全双工连接的正确关闭，`避免RST拒绝服务`。

2. ESTABLISHED:

   表示`数据传输正在进行`

3. CLOSE_WAIT

   正常状态，会`很快转化为LAST_WAIT`,只出现在被动关闭方。

### 历久弥新的HTTP

![image-20210506232400891](https://zyz-img.oss-cn-chengdu.aliyuncs.com/img/image-20210506232400891.png)

------

> 山高路远，静水深流